# AlphaZero Pipeline Configuration

# Game settings
game_type: gomoku
board_size: 15
input_channels: 20
policy_size: 0

# Directory settings
model_dir: models
data_dir: data
log_dir: logs

# Neural network settings
network_type: resnet
use_gpu: true
num_iterations: 10
num_res_blocks: 19
num_filters: 256

# Self-play settings
self_play_num_games: 100
self_play_num_parallel_games: 4
self_play_max_moves: 0
self_play_temperature_threshold: 30
self_play_high_temperature: 1.0
self_play_low_temperature: 0.1

# MCTS settings
mcts_num_simulations: 100
mcts_num_threads: 4
mcts_batch_size: 8
mcts_batch_timeout_ms: 20
mcts_exploration_constant: 1.5
mcts_temperature: 1.0
mcts_add_dirichlet_noise: true
mcts_dirichlet_alpha: 0.3
mcts_dirichlet_epsilon: 0.25

# Training settings
train_epochs: 10
train_batch_size: 256
train_num_workers: 4
train_learning_rate: 0.001
train_weight_decay: 0.0001
train_lr_step_size: 5
train_lr_gamma: 0.1

# Arena/evaluation settings
enable_evaluation: true
arena_num_games: 20
arena_num_parallel_games: 4
arena_num_threads: 4
arena_num_simulations: 100
arena_temperature: 0.1
arena_win_rate_threshold: 0.55
EOF < /dev/null
