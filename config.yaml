# AlphaZero Pipeline Configuration

# Game settings
game_type: gomoku
board_size: 15
policy_size: 0

# Directory settings
model_dir: models
data_dir: data
log_dir: logs

# Neural network settings
network_type: resnet
use_gpu: true
num_iterations: 10
num_res_blocks: 12  # Increased for 8GB VRAM - original was 19
num_filters: 128  # Increased for 8GB VRAM - original was 256
input_channels: 17  # Match Gomoku's enhanced tensor representation (17 planes)

# Self-play settings
self_play_num_games: 100
self_play_num_parallel_games: 1
self_play_max_moves: 0
self_play_temperature_threshold: 30
self_play_high_temperature: 1.0
self_play_low_temperature: 0.1

# MCTS settings
mcts_num_simulations: 100  # Increased from 8 to achieve better play (we fixed the performance issues)
mcts_num_threads: 8  # Reduced thread count to ensure stable batching
mcts_batch_size: 32  # Increased batch size for better GPU throughput
mcts_batch_timeout_ms: 50  # Reduced timeout for more responsive batching
mcts_exploration_constant: 1.5
mcts_temperature: 1.0
mcts_add_dirichlet_noise: true
mcts_dirichlet_alpha: 0.3
mcts_dirichlet_epsilon: 0.25

# Training settings
train_epochs: 10
train_batch_size: 256
train_num_workers: 4  # Increased to maximum for better performance
train_learning_rate: 0.001
train_weight_decay: 0.0001
train_lr_step_size: 5
train_lr_gamma: 0.1

# Arena/evaluation settings
enable_evaluation: true
arena_num_games: 20
arena_num_parallel_games: 4
arena_num_threads: 4
arena_num_simulations: 100
arena_temperature: 0.1
arena_win_rate_threshold: 0.55
