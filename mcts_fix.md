# MCTS Batch Accumulation Debugging Analysis

Based on the logs and code review, there's a critical issue preventing leaf nodes from being generated and added to the batch accumulator. The batch accumulator is correctly initialized and running, but it's not receiving any nodes to process.

## Root Cause Analysis

The primary issue appears to be that **the MCTS search is not properly starting or is getting stuck before generating any leaf nodes**. Let's examine the evidence:

1. **Batch accumulator is running but empty:**
   ```
   üîÑ BatchAccumulator::accumulatorLoop - [Iteration N] current_batch_size=0, total_batches=0, total_items=0
   ```

2. **No leaf evaluations are being submitted:**
   ```
   [BATCH_STATS] Total batches: 0, Avg size: 0, Total states: 0, Target batch: 64, Leaf queue size: 0
   ```

3. **Critical point:** There are no log messages from `MCTSEngine::executeSerialSearch` or `MCTSEngine::selectLeafNode`, which should appear if the search was actually running.

## Technical Details of the Problem

After analyzing the code, I've identified several potential issues:

### 1. The MCTSEngine Search Process Isn't Starting

The `MCTSEngine::runSearch` method should be called from the SelfPlayManager, but there's no evidence in the logs that this is happening. The search process includes these key steps:

```cpp
void MCTSEngine::runSearch(const core::IGameState& state) {
    // Step 1: Create the root node with the current state
    root_ = createRootNode(state);
    
    // Step 2: Initialize game state pool if enabled
    initializeGameStatePool(state);
    
    // Step 3: Set up batch parameters for the evaluator
    setupBatchParameters();
    
    // Step 4: Expand the root node to prepare for search
    if (!root_->isTerminal()) {
        expandNonTerminalLeaf(root_);
    }
    
    // Step 5: Reset search statistics and prepare for new search
    resetSearchState();
    
    // Step 6: Create parallel search roots if root parallelization is enabled
    std::vector<std::shared_ptr<MCTSNode>> search_roots;
    if (settings_.use_root_parallelization && settings_.num_root_workers > 1) {
        search_roots = createSearchRoots(root_, settings_.num_root_workers);
    } else {
        search_roots.push_back(root_);
    }
    
    // Step 7: Execute the main search algorithm
    executeSerialSearch(search_roots);
    
    // Other steps...
}
```

### 2. The Shared Queue Configuration Issue

The logs show that shared queues are being set up:

```
SelfPlayManager: Setting up shared queues for evaluator at addresses leaf_queue=0x7fa338345158, result_queue=0x7fa3383453c0
```

However, there appears to be multiple batch accumulators being created:

```
BatchAccumulator::Constructor - Created with target_size=64, min_viable=1, max_wait=1ms
... (later)
BatchAccumulator::Constructor - Created with target_size=64, min_viable=1, max_wait=1ms
```

This suggests there may be a synchronization issue between the batch accumulators and the shared queues.

### 3. The MCTSEngine selectLeafNode Method May Not Be Finding Leaves

In `MCTSEngine::executeSerialSearch`, the `selectLeafNode` method should be finding leaf nodes:

```cpp
// Find a leaf node for evaluation
auto [leaf, path] = selectLeafNode(current_root);
```

If this method is failing to find leaves, or if the leaves are not being properly added to the batch accumulator, that would explain the observed behavior.

## Solutions

Based on the analysis, here are concrete fixes to resolve the batch accumulation issue:

### 1. Fix the Search Initialization

Add explicit verification in the SelfPlayManager to ensure that each MCTS engine is properly starting the search process:

```cpp
// In SelfPlayManager's game-playing method
for (auto& engine : mcts_engines_) {
    std::cout << "SelfPlayManager: Starting search with engine " << &engine << std::endl;
    
    try {
        auto result = engine.runSearch(current_state);
        std::cout << "SelfPlayManager: Search completed with " 
                 << result.stats.total_nodes << " nodes explored" << std::endl;
    } catch (const std::exception& e) {
        std::cerr << "ERROR: Exception during search: " << e.what() << std::endl;
        // Handle the error appropriately
    }
}
```

### 2. Fix the Shared Queue Management

Ensure that only one batch accumulator is being used across all engines:

```cpp
// In SelfPlayManager's initialization
std::shared_ptr<MCTSEvaluator> shared_evaluator = std::make_shared<MCTSEvaluator>(
    inference_function, batch_size, batch_timeout);

// Set up shared queues
moodycamel::ConcurrentQueue<PendingEvaluation> shared_leaf_queue;
moodycamel::ConcurrentQueue<std::pair<NetworkOutput, PendingEvaluation>> shared_result_queue;
shared_evaluator->setExternalQueues(&shared_leaf_queue, &shared_result_queue, notify_callback);

// Use the same evaluator for all engines
for (auto& engine : mcts_engines_) {
    engine.setSharedEvaluator(shared_evaluator);
}
```

### 3. Add Debug Points in Critical Functions

Add specific debug statements to trace the leaf node generation and batch accumulation process:

```cpp
// In MCTSEngine::executeSerialSearch main loop
while (active_simulations_.load(std::memory_order_acquire) > 0) {
    std::cout << "DEBUG: MCTSEngine::executeSerialSearch - Main loop iteration with " 
             << active_simulations_.load() << " active simulations" << std::endl;
    
    // Rest of the loop...
}

// In MCTSEngine::selectLeafNode
std::cout << "DEBUG: MCTSEngine::selectLeafNode - Starting leaf selection for root " 
         << root.get() << std::endl;
// Function logic...
std::cout << "DEBUG: MCTSEngine::selectLeafNode - Found leaf " 
         << (leaf ? leaf.get() : nullptr) << std::endl;

// In MCTSEngine::expandAndEvaluate
std::cout << "DEBUG: MCTSEngine::expandAndEvaluate - Expanding leaf " 
         << leaf.get() << std::endl;
```

### 4. Fix the direct submission to BatchAccumulator

The critical fix in the `executeSerialSearch` method needs to be checked:

```cpp
// CRITICAL FIX: If using external evaluator with BatchAccumulator,
// directly add to the BatchAccumulator instead of just storing in leaf_batch
if (use_shared_queues_ && evaluator_ && evaluator_->getBatchAccumulator()) {
    BatchAccumulator* accumulator = evaluator_->getBatchAccumulator();
    if (accumulator) {
        // Verify accumulator is working properly
        std::cout << "VERIFICATION: MCTSEngine adding leaf to accumulator, isRunning=" 
                 << accumulator->isRunning() << std::endl;
        
        // Add to the accumulator directly
        accumulator->addEvaluation(std::move(pending));
        
        // IMPORTANT: Make sure notifications are sent
        if (external_queue_notify_fn_) {
            external_queue_notify_fn_();
        }
    }
}
```

### 5. Address the min_viable_batch_size Override

The batch accumulator is overriding the min_viable_batch_size:

```
‚ö†Ô∏è BatchAccumulator::Constructor - CRITICAL OVERRIDE: Always using min_viable=1, max_wait=1ms regardless of input parameters (64, 100ms)
```

While this shouldn't prevent batch accumulation entirely, it might be causing inefficient batching. Modify the constructor to accept the specified parameters:

```cpp
BatchAccumulator::BatchAccumulator(size_t target_batch_size, 
                                  size_t min_viable_batch_size,
                                  std::chrono::milliseconds max_wait_time)
    : target_batch_size_(target_batch_size),
      min_viable_batch_size_(min_viable_batch_size), // Use the provided value
      max_wait_time_(max_wait_time), // Use the provided value
      batch_start_time_(std::chrono::steady_clock::now()) {
    
    // Ensure sensible defaults
    if (target_batch_size_ < 8) target_batch_size_ = 8;
    if (min_viable_batch_size_ < 1) min_viable_batch_size_ = target_batch_size_ * 3 / 4;
    if (max_wait_time_.count() < 1) max_wait_time_ = std::chrono::milliseconds(50);
    
    std::cout << "BatchAccumulator::Constructor - Created with target_size=" << target_batch_size_
              << ", min_viable=" << min_viable_batch_size_
              << ", max_wait=" << max_wait_time_.count() << "ms" << std::endl;
    
    // Pre-allocate batch to avoid reallocations
    current_batch_.reserve(target_batch_size_ * 2);
}
```

## Additional Recommendations

1. **Verify game state creation:** Ensure the SelfPlayManager is correctly creating and passing game states to the MCTS engines.

2. **Check thread management:** The current implementation uses multiple threads for batch processing. Verify thread synchronization to avoid deadlocks.

3. **Simplify debugging:** Temporarily reduce the complexity:
   - Disable root parallelization
   - Use a smaller batch size
   - Increase logging in key MCTS functions

4. **Add timing information:** Add timestamps to logs to identify potential hanging or slow operations.

5. **Inspect the neural network inference:** Verify that the neural network model is being loaded correctly and can perform inference.

By implementing these fixes and recommendations, you should be able to identify and resolve the batch accumulation issue. The primary focus should be on ensuring that the MCTS search process actually starts and generates leaf nodes for evaluation.