# Aggressive DDW-RandWire-ResNet Configuration for Maximum GPU Utilization
# For RTX 3060 Ti (8GB VRAM) + Ryzen 9 5900X + 64GB RAM
# Based on optimized ResNet configuration with aggressive scaling

# Game settings
game_type: gomoku
board_size: 9  # Changed to 9 to match optimized config
input_channels: 17  # Gomoku enhanced representation with history

# Network configuration
network_type: ddw_randwire

# Model path
model_path: models/ddw_randwire_model_aggressive.pt

# DDW-RandWire-ResNet - Aggressive but memory-aware settings
ddw_channels: 96          # Reduced from 128 for memory efficiency
ddw_num_blocks: 12        # Reduced from 20 to prevent OOM
ddw_num_nodes: 24         # Reduced from 32 for stability
ddw_graph_method: barabasi_albert  # Scale-free for hub nodes
ddw_ba_m: 8              # More connections per node
ddw_dynamic_routing: true # Dynamic routing for full DDW benefits
ddw_seed: 42             # Fixed seed for reproducibility

# MCTS - Optimized from fixed config with aggressive scaling
mcts_simulations: 1000    # Increased from 800
mcts_threads_per_engine: 12  # Match optimized config
mcts_batch_size: 384      # Increased from 256 for more GPU usage
mcts_batch_timeout_ms: 2  # Keep short for responsiveness
mcts_c_puct: 1.0         # Match optimized config
mcts_virtual_loss: 3.0
mcts_enable_transposition: true
mcts_temperature: 1.0
mcts_temp_threshold: 10
mcts_dirichlet_alpha: 0.25
mcts_dirichlet_epsilon: 0.25
mcts_use_progressive_widening: true
mcts_progressive_widening_c: 1.0
mcts_progressive_widening_k: 10.0
mcts_transposition_table_size_mb: 128  # Increased for more caching

# Maximum parallelism - Balanced for stability
num_parallel_workers: 10  # Reduced from 12 for stability
num_games: 1000          # Reduced from 2000 for testing
save_interval: 50        # More frequent saves
output_dir: data/self_play_games_ddw_aggressive
max_game_length: 200
clear_pools_every_n_games: 5       # More aggressive cleanup
force_gpu_cleanup_every_n_games: 10

# Memory settings - Aggressive usage for 64GB RAM
max_memory_gb: 56        # Use up to 56GB (87.5% of 64GB)
cleanup_threshold_gb: 40  # Warning at 40GB (62.5% of 64GB)
emergency_cleanup_gb: 48  # Critical at 48GB (75% of 64GB)
enable_memory_pool: true
tensor_pool_size: 2048    # Doubled from optimized
node_pool_initial_size: 20000
node_pool_max_size: 200000  # Doubled from optimized
game_state_pool_size: 2000  # Doubled from optimized
check_interval_ms: 100      # More frequent checks
cleanup_interval_ms: 1000   # More frequent cleanup

# GPU optimization
cuda_device: 0
gpu_memory_fraction: 0.9   # Reduced from 0.98 for stability
enable_mixed_precision: false  # Keep false for stability
cudnn_benchmark: true     # Auto-tune convolutions
pin_memory: true          # Faster CPU-GPU transfer

# Advanced DDW settings for performance
ddw_routing_temperature: 0.8    # Slightly focused routing
ddw_edge_dropout: 0.0
ddw_progressive_depth: false
ddw_cache_routing: true         # Cache routing decisions

# Batch collection optimization
enable_burst_mode: true          # Collect leaves in bursts
burst_collection_size: 32        # Collect 32 leaves at once
min_viable_batch_ratio: 0.75     # Process at 75% full
max_batch_wait_ms: 25           # Maximum wait time

# Performance monitoring
enable_profiling: true
profile_interval: 1000
log_interval: 50
monitor_gpu_usage: true
gpu_usage_target: 95      # Target 95% GPU utilization

# Training settings for aggressive GPU usage
train_batch_size: 128     # Large batch for training
train_accumulation_steps: 2  # Gradient accumulation
train_learning_rate: 0.002
train_epochs: 30
train_num_workers: 8      # More data loading workers

# Advanced optimizations
enable_graph_optimization: true   # Optimize computation graph
use_tensorrt: false              # Keep false unless you have TensorRT
enable_cuda_graphs: true         # CUDA graphs for lower overhead
async_gpu_transfer: true         # Asynchronous memory transfers

# Expected performance with these settings:
# - GPU utilization: 90-98%
# - GPU memory usage: ~7.5GB
# - Throughput: ~2000-3000 MCTS simulations/second
# - Games per hour: ~200-300 (depending on game length)

# WARNING: These aggressive settings may cause:
# - Higher GPU temperatures (ensure good cooling)
# - Occasional CUDA out of memory errors (reduce batch_size if this happens)
# - Higher system memory usage (monitor with htop)