# Omoknuni App Flow Document

## Onboarding and Sign-In/Sign-Up
A brand-new developer begins by cloning the Omoknuni repository from the project’s GitHub page. They navigate into the repository folder and invoke the CMake build system, running `cmake -B build` followed by `cmake --build build` to compile the C++ core engine and Python bindings. Once compilation completes, they install the Python package in editable mode by running `pip install -e .` from the project root. At this point no user accounts or sign-in steps are needed, as Omoknuni is delivered as a locally executed command-line tool. The user then sets environment variables `OMOKNUNI_MODEL_DIR` and `OMOKNUNI_DATA_DIR` to the paths where model checkpoints and game records will be stored. With these steps done, the developer is ready to invoke the CLI for all key flows.

## Main Dashboard or Home Page
After installation, invoking `omoknuni-cli` with no additional arguments prints a welcome message and a summary of available commands. The default view shows a brief description of Omoknuni along with four primary command groups: `self-play` for generating training data, `train` for updating network weights, `eval` for strength assessment, and `play` for interactive human-versus-AI games. A help flag is always available, so the user can type `omoknuni-cli --help` or `omoknuni-cli <command> --help` to see detailed options. This command-line menu serves as the main hub from which every major feature flow is launched.

## Detailed Feature Flows and Page Transitions
When the developer starts self-play by running `omoknuni-cli self-play --config config.yaml`, the Python orchestrator reads the YAML file and spawns multiple MCTS worker threads in C++. These workers simulate games in parallel, each worker traversing the search tree until it reaches a leaf node. Leaf states are batched together in a centralized queue powered by moodycamel::ConcurrentQueue. A dedicated evaluator thread collects these leaf states until either the batch size threshold or the timeout is reached. The evaluator then performs a batched libtorch inference on the GPU and returns policy and value outputs to the waiting worker threads. Completed games are serialized into flat files under `OMOKNUNI_DATA_DIR`, and periodic ELO updates and batch latency statistics are appended to a running log file. Each new game file and log entry appears as soon as a game concludes or a reporting interval passes.

When enough games are available, the user transitions to the training flow by issuing `omoknuni-cli train --config config.yaml`. The orchestrator reads the same configuration file to determine neural network hyperparameters, learning rate schedules, and checkpoint paths. Training data is loaded in mini-batches directly from the flat files, converted into tensors, and fed into the DDW-RandWire-ResNet model via libtorch. After each epoch or step interval, model weights are serialized to `OMOKNUNI_MODEL_DIR`. Training metrics such as loss, accuracy, GPU memory usage, and time per batch are printed to the console and appended to a structured log file for later analysis.

To assess the model’s playing strength, the developer invokes `omoknuni-cli eval --config config.yaml`. This flow pits the latest checkpointed network against the previous best model in head-to-head games. MCTS search with the same batch inference mechanism powers both sides. Win rates, ELO deltas, and match durations are reported in real time and written to an evaluation log. If the new network outperforms the champion, the system can optionally rotate the checkpoint pointers so that the latest model becomes the new benchmark.

Finally, for interactive play, the user types `omoknuni-cli play --config config.yaml`. A command-line session opens where the developer enters moves in algebraic notation (for Chess) or coordinate pairs (for Gomoku and Go). After each human move, the engine runs MCTS with leaf batching and displays its chosen move. The session continues until game end, after which a summary of move counts and final statistics is shown.

## Settings and Account Management
All runtime settings are controlled by a single YAML configuration file. The developer edits this file to set the target game type, the number of MCTS simulations, virtual loss parameters, batch size, network architecture options, optimizer settings, checkpoint intervals, and logging verbosity. Model and data directories are also declared here. If the user wants to switch from Gomoku to Chess, they update the `game: chess` field and rerun any flow command. After adjusting settings, the user simply invokes the desired CLI command again. There is no separate account or permissions system, and returning to the main command-line menu is as simple as exiting the current command or pressing Ctrl+C to abort and then reissuing `omoknuni-cli`.

## Error States and Alternate Paths
If the configuration file is missing or malformed, the CLI immediately prints an error message showing which field is invalid and suggests the correct YAML key. When required model checkpoint files are absent in `OMOKNUNI_MODEL_DIR`, the tool reports the missing path and aborts the flow, prompting the user to train or download a model. GPU initialization failures—due to missing drivers or incompatible CUDA versions—are caught at startup, and the engine falls back to CPU-only inference while printing a warning. During MCTS search, if the batch inference queue fails to collect any leaves within the timeout window, the evaluator proceeds with any states available to avoid deadlocks. In case of I/O errors writing game data or logs, the CLI reports the file path and suggests checking permissions. All errors exit with a nonzero status code so that scripts or CI pipelines can detect failures automatically.

## Conclusion and Overall App Journey
From cloning and building the repository to launching commands for self-play, training, evaluation, and interactive play, the developer experiences a seamless, text-based journey. Onboarding involves only local steps and no user accounts. The main CLI menu serves as the anchor point for all flows. Detailed feature paths ensure that leaf states are batched for GPU efficiency and results are returned to MCTS workers without manual intervention. Settings are managed in a single YAML file, and robust error handling guides the user back to a working state. In everyday usage, the developer iterates between generating self-play data, improving the neural network, and measuring progress, all under the consistent Omoknuni branding and MIT license.