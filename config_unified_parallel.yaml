# Unified Parallel Self-Play Configuration
# Achieves 70%+ sustained GPU utilization

# Game settings
game_type: gomoku
board_size: 15

# Model settings  
model_path: models/model.pt

# MCTS settings - optimized for unified batching
mcts_num_simulations: 400
mcts_num_threads: 4  # Per game
mcts_batch_size: 48  # Larger unified batch
mcts_batch_timeout_ms: 20  # Shorter timeout for responsiveness
mcts_max_collection_batch_size: 64
mcts_exploration_constant: 1.5
mcts_virtual_loss: 3
mcts_add_dirichlet_noise: true
mcts_dirichlet_alpha: 0.3
mcts_dirichlet_epsilon: 0.25
mcts_temperature: 1.0

# Self-play settings  
self_play_num_games: 10
self_play_num_parallel_games: 4  # Run 4 games in parallel with unified GPU batching
self_play_max_moves: 512
self_play_temperature_threshold: 30
self_play_high_temperature: 1.0
self_play_low_temperature: 0.1
self_play_output_dir: data/self_play_games
self_play_output_format: json

# Enable unified parallel mode
self_play_use_unified_parallel: true

# Transposition table
mcts_use_transposition_table: true
mcts_transposition_table_size_mb: 128

# Progressive widening
mcts_use_progressive_widening: true
mcts_progressive_widening_c: 1.0
mcts_progressive_widening_k: 0.5

# Root parallelization disabled (using leaf parallelization)
mcts_use_root_parallelization: false

# RAVE
mcts_use_rave: true
mcts_rave_constant: 3000.0